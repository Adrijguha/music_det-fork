{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WUCKw8Nn7NQ",
        "outputId": "1c679682-6562-414e-e268-ee1cebdbb6a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blues.00001.wav      inspirational-symphony-classical-music-loop-243157.mp3  sample_data\n",
            "classical.00000.wav  MusicGenre_CNN_79.73.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leO3ki9fnm6c",
        "outputId": "cba7565a-2892-4abe-bff0-abdfb7a1b8b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "Predicted Genre: reggae\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-891d308d3ec8>:65: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  predicted_genre = genre_dict[int(predicted_index)]\n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import math # Import the math module\n",
        "\n",
        "# ... (rest of your code) ...\n",
        "# Load the saved model\n",
        "model = keras.models.load_model(\"MusicGenre_CNN_79.73.h5\")\n",
        "\n",
        "# Function to preprocess the audio file\n",
        "def process_input(audio_file, track_duration):\n",
        "    SAMPLE_RATE = 22050\n",
        "    NUM_MFCC = 13\n",
        "    N_FTT = 2048\n",
        "    HOP_LENGTH = 512\n",
        "    TRACK_DURATION = track_duration  # measured in seconds\n",
        "    SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
        "    NUM_SEGMENTS = 10\n",
        "\n",
        "    samples_per_segment = int(SAMPLES_PER_TRACK / NUM_SEGMENTS)\n",
        "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / HOP_LENGTH)\n",
        "\n",
        "    signal, sample_rate = librosa.load(audio_file, sr=SAMPLE_RATE)\n",
        "\n",
        "    # Extract MFCCs for the first segment\n",
        "    start = samples_per_segment * 0\n",
        "    finish = start + samples_per_segment\n",
        "    mfcc = librosa.feature.mfcc(y=signal[start:finish], sr=sample_rate, n_mfcc=NUM_MFCC, n_fft=N_FTT, hop_length=HOP_LENGTH)\n",
        "\n",
        "    mfcc = mfcc.T\n",
        "\n",
        "    return mfcc\n",
        "\n",
        "# Dictionary to map predicted index to genre\n",
        "genre_dict = {\n",
        "    0: \"disco\",\n",
        "    1: \"pop\",\n",
        "    2: \"classical\",\n",
        "    3: \"metal\",\n",
        "    4: \"rock\",\n",
        "    5: \"blues\",\n",
        "    6: \"hiphop\",\n",
        "    7: \"reggae\",\n",
        "    8: \"country\",\n",
        "    9: \"jazz\",\n",
        "}\n",
        "\n",
        "# Path to your audio file\n",
        "audio_file_path = \"inspirational-symphony-classical-music-loop-243157.mp3\"\n",
        "\n",
        "# Preprocess the audio\n",
        "new_input_mfcc = process_input(audio_file_path, 30)\n",
        "\n",
        "# Reshape the input for the model\n",
        "X_to_predict = new_input_mfcc[np.newaxis, ..., np.newaxis]\n",
        "\n",
        "# Make the prediction\n",
        "prediction = model.predict(X_to_predict)\n",
        "\n",
        "# Get the predicted genre\n",
        "predicted_index = np.argmax(prediction, axis=1)\n",
        "predicted_genre = genre_dict[int(predicted_index)]\n",
        "\n",
        "print(\"Predicted Genre:\", predicted_genre)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr  # Import Gradio for building the UI\n",
        "import librosa  # For audio processing\n",
        "import numpy as np  # For numerical operations\n",
        "from tensorflow import keras  # For loading the trained model\n",
        "import math  # For mathematical calculations\n",
        "\n",
        "# Load the pre-trained model for genre classification\n",
        "model = keras.models.load_model(\"MusicGenre_CNN_79.73.h5\")\n",
        "\n",
        "# Function to preprocess the audio file\n",
        "def process_input(audio_file, track_duration=30):\n",
        "    SAMPLE_RATE = 22050  # Sample rate for audio processing\n",
        "    NUM_MFCC = 13  # Number of MFCCs to extract\n",
        "    N_FTT = 2048  # Number of samples per FFT\n",
        "    HOP_LENGTH = 512  # Number of samples between successive frames\n",
        "    TRACK_DURATION = track_duration  # Duration of the audio to process (in seconds)\n",
        "    SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION  # Total samples in the track\n",
        "    NUM_SEGMENTS = 10  # Number of segments to split the audio into\n",
        "\n",
        "    # Calculate samples and MFCC vectors per segment\n",
        "    samples_per_segment = int(SAMPLES_PER_TRACK / NUM_SEGMENTS)\n",
        "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / HOP_LENGTH)\n",
        "\n",
        "    # Load the audio file and resample it\n",
        "    signal, sample_rate = librosa.load(audio_file, sr=SAMPLE_RATE)\n",
        "\n",
        "    # Extract MFCCs for the first segment\n",
        "    start = samples_per_segment * 0  # Start index of the first segment\n",
        "    finish = start + samples_per_segment  # End index of the first segment\n",
        "    mfcc = librosa.feature.mfcc(\n",
        "        y=signal[start:finish],\n",
        "        sr=sample_rate,\n",
        "        n_mfcc=NUM_MFCC,\n",
        "        n_fft=N_FTT,\n",
        "        hop_length=HOP_LENGTH,\n",
        "    )\n",
        "\n",
        "    # Transpose the MFCC array to make it suitable for the model\n",
        "    mfcc = mfcc.T\n",
        "    return mfcc\n",
        "\n",
        "# Dictionary to map the model's predicted index to a genre\n",
        "genre_dict = {\n",
        "    0: \"disco\",\n",
        "    1: \"pop\",\n",
        "    2: \"classical\",\n",
        "    3: \"metal\",\n",
        "    4: \"rock\",\n",
        "    5: \"blues\",\n",
        "    6: \"hiphop\",\n",
        "    7: \"reggae\",\n",
        "    8: \"country\",\n",
        "    9: \"jazz\",\n",
        "}\n",
        "\n",
        "# Function to predict the genre of the audio file\n",
        "def predict_genre(audio_file):\n",
        "    # Preprocess the uploaded audio file\n",
        "    new_input_mfcc = process_input(audio_file, 30)\n",
        "    # Reshape the input to match the model's expected input shape\n",
        "    X_to_predict = new_input_mfcc[np.newaxis, ..., np.newaxis]\n",
        "    # Make the prediction using the loaded model\n",
        "    prediction = model.predict(X_to_predict)\n",
        "    # Get the genre index with the highest probability\n",
        "    predicted_index = np.argmax(prediction, axis=1)\n",
        "    # Map the predicted index to the genre name\n",
        "    predicted_genre = genre_dict[int(predicted_index)]\n",
        "    return f\"Predicted Genre: {predicted_genre}\"\n",
        "\n",
        "# Create the Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict_genre,  # Function to be executed when user uploads a file\n",
        "    inputs=gr.Audio( type=\"filepath\"),  # Accept uploaded audio files\n",
        "    outputs=\"text\",  # Display the prediction as text\n",
        "    title=\"Music Genre Classifier\",  # Title of the app\n",
        "    description=\"Upload an audio file to predict its genre.\",  # Short description\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tZp1G-HsK9rr",
        "outputId": "4cf620c1-667b-4394-c015-ada2a79de6bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.12.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.5.4 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.4)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.1)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.4->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.4->gradio) (14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://04318c89952905a27d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://04318c89952905a27d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    }
  ]
}